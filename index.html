<!DOCTYPE html>
<html>
  <head>
    <title>SMLLE Demos</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
    <script src="load_table.js" defer></script>
    <style>
      @import url(https://fonts.googleapis.com/css?family=Open+Sans);
      body {
        font-family: 'Open-Sans', sans-serif;
        font-weight: 300;
        background-color: #fff;
      }
      td {
        vertical-align: middle;
        text-align: justify;
        width: 0vw;
        min-width: 250px;
      }
      audio {
        width: 14vw;
        min-width: 100px;
      }
      .content {
        width: 69vw;
        padding: 25px 50px;
        margin: 25px auto;
        background-color: white;
        box-shadow: 0px 0px 10px #999;
        border-radius: 15px;
        font-family: "Google Sans";
      }
      .contentblock {
        width: 950px;
        margin: 0 auto;
        padding: 0;
        border-spacing: 25px 0;
      }
      .contentblock td {
        background-color: #fff;
        padding: 25px 50px;
        vertical-align: top;
        box-shadow: 0px 0px 10px #999;
        border-radius: 15px;
      }
      a, a:visited {
        color: #224b8d;
        font-weight: 300;
      }
      #authors {
        text-align: center;
        margin-bottom: 20px;
        font-size: 20px;
      }
      #conference {
        text-align: center;
        margin-bottom: 20px;
        font-style: italic;
      }
      #authors a {
        margin: 0 10px;
      }
      h1 {
        text-align: center;
        font-size: 35px;
        font-weight: 300;
      }
      h2 {
        font-size: 30px;
        font-weight: 300;
      }
      h3 {
        font-size: 25px;
        font-weight: 300;
      }
      h4 {
        font-size: 20px;
        font-weight: 300;
      }
      code {
        display: block;
        padding: 10px;
        margin: 10px 10px;
      }
      p {
        line-height: 25px;
        text-align: justify;
      }
      p code {
        display: inline;
        padding: 0;
        margin: 0;
      }
      #teasers {
        margin: 0 auto;
      }
      #teasers td {
        margin: 0 auto;
        text-align: center;
        padding: 5px;
      }
      #teasers img {
        width: 250px;
      }
      #results img {
        width: 133px;
      }
      #seeintodark {
        margin: 0 auto;
      }
      #sift {
        margin: 0 auto;
      }
      #sift img {
        width: 250px;
      }
      .downloadpaper {
        padding-left: 20px;
        float: right;
        text-align: center;
      }
      .downloadpaper a {
        font-weight: bold;
        text-align: center;
      }
      .teaser-img {
        width: 80%;
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .teaser-gif {
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .summary-img {
        width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
      .video-iframe {
        width: 1000;
        height: 800;
        margin: auto;
        display: block;
      }
      .container {
        display: flex;
        align-items: center;
        justify-content: center
      }
      .image {
        flex-basis: 40%
      }
      .text {
        font-size: 20px;
        padding-left: 20px;
      }
      .center {
        margin-left: auto;
        margin-right: auto;
      }
      .boxshadow {
        border: 1px solid;
        padding: 10px;
        box-shadow: 2px 2px 5px #888888;
      }
      .spacertr {
        height: 8px;
      }
      .spacertd {
        width: 40px;
      }
    </style>
  </head>
  <body>
    <div class="content">
      <div class="text-center">
        <h1><strong>SMLLE: Zero-Shot Streaming Text to Speech Synthesis with Transducer and Auto-Regressive Modeling</strong></h1>
        <h5></h5>
        <!-- <span style="font-size: 24px">Anonymous</span></p> -->
        <!-- <p class="lead fw-bold">
          |<a
            href=""
            class="btn border-white bg-white fw-bold"
            >paper</a
          >|
        </p> -->
      </div>
        <!-- <h4 style="text-align:center;">[<a href="#">Paper</a>] [<a href="pdfs/appendix.pdf">Appendix</a>]</h4> -->
        <h2 style="text-align:center;">Abstract</h2>
        <div style="text-align: justify;">
           <!-- With the help of discrete neural audio codecs, large language models (LLM) have increasingly been recognized as a promising methodology for zero-shot Text-to-Speech (TTS) synthesis. However, sampling based decoding strategies bring astonishing diversity to generation, but also pose robustness issues such as typos, omissions and repetition. In addition, the high sampling rate of audio also brings huge computational overhead to the inference process of autoregression. To alleviate these issues, we propose <b>VALL-E R</b>, which is a robust and efficiency zero-shot TTS system. Specifically, it introduces phoneme monotonic alignment strategy to enhance the connection between phonemes and acoustic sequence. And merge codec is adopt to downsample the discrete codes in shallow layer without affecting the speech quality. Benefit from these strategies, VALL-E R obtains controllablity over phonemes and demonstrates its strong robustness by approaching the WER of ground truth in experimental results. In addition, it requires fewer autoregressive steps during inference, resulting in over 60\% time savings in inference time. <br> -->

           Zero-shot streaming text-to-speech is an important research topic in human-computer interaction. Existing methods primarily use a lookahead mechanism, relying on future text to achieve natural streaming speech synthesis, which introduces high processing latency. To address this issue, we propose SMLLE, a streaming framework for generating high-quality speech frame-by-frame. SMLLE employs a Transducer to convert text into semantic tokens in real time while simultaneously obtaining duration alignment information. The combined outputs are then fed into a fully autoregressive (AR) streaming model to reconstruct mel-spectrograms. To further stabilize the generation process, we design a Delete \(\langle Bos \rangle\) Mechanism that allows the AR model to access future text introducing as minimal delay as possible. Experimental results suggest that the SMLLE outperforms current streaming TTS methods and achieves comparable performance over sentence-level TTS systems. <br>

           This page is for <b>research demonstration purposes only</b>.
        </div>
      </p>
    </div>
    <div class="content">
      <h2 id="model-overview" style="text-align: center;">Architecture Overview</h2>
      <body>
      <p style="text-align: center;">
        <img src="picture/SMLLE_framework.png" style="width: 45vw; margin-left: 0vw;">
      </p>
        <div style="text-align: justify;">
          The overview of SMLLE. SMLLE has two key components: (1) A Transducer based streaming model to generate the semantic tokens, based on the text.
          (2) An AR streaming model to generate the mel spectrum sequence for the final speech reconstruction, based on the semantic token sequence generated by the first component and the duration-aligned text with the duration information from the Transducer model.
        </div>
      </body>
    </div>


    <div class="content">
      <h2 style="text-align: center;">Samples for Cross-Sentence Voice Clone</h2>
      <div style="text-align: justify;">
        <b>Text</b>: Text transcription. <br>
        <b>GroundTruth</b>: The acoustic groundtruth. <br>
        <b>SMLLE-Transducer</b>: Speech waveform generated by proposed SMLLE Transducer Stage. <br>
        <b>SMLLE-Mel AR</b>: Speech waveform generated by proposed SMLLE Autoregressive Stage. <br>
        <b>MELLE</b>: Speech waveform generated by baseline MELLE. <br>
        <b>VALL-E</b>: Speech waveform generated by baseline VALL-E. <br>
        <b>YourTTS</b>: Speech waveform generated by baseline YourTTS. <br>
      </div>
      <div style="margin-top: 0vh; text-align: center;">
        <div class="table-responsive pt-3">
          <ul class="pagination justify-content-center">
            <li class="page-item active">
              <a id="cross-1" class="page-link" href="#">1</a>
            </li>
            <!-- <li class="page-item">
              <a id="cross-2" class="page-link" href="#">2</a>
            </li> -->
          </ul>
          <table class="table pt-2" id="cross">
            <thead>
              <tr>
                <th>Text</th>
                <th style="text-align: center">GroundTruth</th>
                <th style="text-align: center">SMLLE-Transducer</th>
                <th style="text-align: center">SMLLE-Mel AR</th>
                <th style="text-align: center">MELLE</th>
                <th style="text-align: center">VALL-E</th>
                <th style="text-align: center">YourTTS</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>
    </div>

    <div class="content">
      <h2 id="model-overview" style="text-align: center;">Ethics Statement</h2>
      <div style="text-align: justify;">
        Since SMLLE could synthesize speech that maintains speaker identity, it may carry potential risks in misuse of the model, such as spoofing voice identification or impersonating a specific speaker. We conducted the experiments under the assumption that the user agrees to be the target speaker in speech synthesis. If the model is generalized to unseen speakers in the real world, it should include a protocol to ensure that the speaker approves the use of their voice and a synthesized speech detection model.
      </div>
    </div>
    
    <p style="text-align: center;">
      <img src="https://badges.toozhao.com/badges/01HW75WW0HVJR8Q66FJKQ7ZE07/green.svg" />
    </p>
    </body>

  </body>
</html>

